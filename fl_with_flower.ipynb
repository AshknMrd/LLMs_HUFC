{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ESpKTVP3F_Xt"
      },
      "source": [
        "# Federated Learning using Hugging Face and Flower\n",
        "\n",
        "This tutorial will show how to leverage Hugging Face to federate the training of language models over multiple clients using [Flower](https://flower.dev/). More specifically, we will fine-tune a pre-trained Transformer model (alBERT) for sequence classification over a dataset of IMDB ratings. The end goal is to detect if a movie rating is positive or negative.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hcUWBC4ih-mp"
      },
      "source": [
        "## Dependencies\n",
        "\n",
        "For this tutorial we will need `datasets`, `flwr['simulation']`(here we use the extra 'simulation' dependencies from Flower as we will simulated the federated setting inside Google Colab), `torch`, and `transformers`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBuj5kSif2yt"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate flwr torch transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install \"flwr[simulation]\" ray"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5I0ZUC4hpua"
      },
      "source": [
        "We can now import the relevant modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IhNwuY-Oefau"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import flwr as fl\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from datasets import load_dataset\n",
        "from evaluate import load as load_metric\n",
        "\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import logging"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "J-gZqELEhsun"
      },
      "source": [
        "Next we will set some global variables and disable some of the logging to clear out our output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AH0Sx53Rehjc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The selected device is: cpu\n"
          ]
        }
      ],
      "source": [
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "# DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"The selected device is: {DEVICE}\")\n",
        "CHECKPOINT = \"albert-base-v2\"  # transformer model checkpoint\n",
        "NUM_CLIENTS = 2\n",
        "NUM_ROUNDS = 3"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aI21VQX-GRSb"
      },
      "source": [
        "## Standard Hugging Face workflow\n",
        "\n",
        "### Handling the data\n",
        "\n",
        "To fetch the IMDB dataset, we will use Hugging Face's `datasets` library. We then need to tokenize the data and create `PyTorch` dataloaders, this is all done in the `load_data` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(num_clients: int, num_samples_per_client: int = None):\n",
        "    \"\"\"Load IMDB data (training and eval)\"\"\"\n",
        "    raw_datasets = load_dataset(\"imdb\")\n",
        "    raw_datasets = raw_datasets.shuffle(seed=42)\n",
        "\n",
        "    # remove unnecessary data split\n",
        "    del raw_datasets[\"unsupervised\"]\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "    def split_indices(dataset_len):\n",
        "        indices = random.sample(range(dataset_len), dataset_len) \n",
        "        if num_samples_per_client:\n",
        "            total = num_clients * num_samples_per_client\n",
        "            indices = indices[:total]\n",
        "            return [indices[i * num_samples_per_client:(i + 1) * num_samples_per_client] for i in range(num_clients)]\n",
        "        else:\n",
        "            return [indices[i::num_clients] for i in range(num_clients)]  \n",
        "\n",
        "    tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "    train_indices = split_indices(len(tokenized_datasets[\"train\"]))\n",
        "    test_indices = split_indices(len(tokenized_datasets[\"test\"]))\n",
        "\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns(\"text\")\n",
        "    tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    trainloader = [DataLoader(tokenized_datasets[\"train\"].select(idxs), shuffle=True, batch_size=32, collate_fn=data_collator) for idxs in train_indices]\n",
        "    testloader = [DataLoader(tokenized_datasets[\"test\"].select(idxs), shuffle=False, batch_size=32, collate_fn=data_collator) for idxs in test_indices]\n",
        "\n",
        "    return trainloader, testloader\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s1UtfzMFGVKF"
      },
      "source": [
        "### Training and testing the model\n",
        "\n",
        "Once we have a way of creating our trainloader and testloader, we can take care of the training and testing. This is very similar to any `PyTorch` training or testing loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "szd1PmUbem1v"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader, epochs):\n",
        "    optimizer = torch.optim.AdamW(net.parameters(), lr=5e-5)\n",
        "    net.train()\n",
        "    for _ in range(epochs):\n",
        "        for batch in trainloader:\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "            outputs = net(**batch)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    metric = load_metric(\"accuracy\")\n",
        "    loss = 0\n",
        "    net.eval()\n",
        "    for batch in testloader:\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = net(**batch)\n",
        "        logits = outputs.logits\n",
        "        loss += outputs.loss.item()\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = metric.compute()[\"accuracy\"]\n",
        "    return loss, accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rVbWtgQLGhFB"
      },
      "source": [
        "### Creating the model itself\n",
        "\n",
        "To create the model itself, we will just load the pre-trained alBERT model using Hugging Face’s `AutoModelForSequenceClassification` :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qeiueaYKGiBf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable parameters: 11,685,122\n"
          ]
        }
      ],
      "source": [
        "net = AutoModelForSequenceClassification.from_pretrained(\n",
        "    CHECKPOINT, num_labels=2\n",
        ").to(DEVICE)\n",
        "\n",
        "num_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
        "print(f\"Trainable parameters: {num_params:,}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx95k0TUGtSG"
      },
      "source": [
        "## Federating the example\n",
        "\n",
        "The idea behind Federated Learning is to train a model between multiple clients and a server without having to share any data. This is done by letting each client train the model locally on its data and send its parameters back to the server, which then aggregates all the clients’ parameters together using a predefined strategy. This process is made very simple by using the [Flower](https://github.com/adap/flower) framework. If you want a more complete overview, be sure to check out this guide: [What is Federated Learning?](https://flower.dev/docs/tutorial/Flower-0-What-is-FL.html)\n",
        "\n",
        "### Creating the IMDBClient\n",
        "\n",
        "To federate our example to multiple clients, we first need to write our Flower client class (inheriting from `flwr.client.NumPyClient`). This is very easy, as our model is a standard `PyTorch` model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-sSuLWYzeuPC"
      },
      "outputs": [],
      "source": [
        "class IMDBClient(fl.client.NumPyClient):\n",
        "    def __init__(self, net, trainloader, testloader):\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return [val.cpu().numpy() for _, val in self.net.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        params_dict = zip(self.net.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        self.net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        print(\"Training Started...\")\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        print(\"Training Finished.\")\n",
        "        return self.get_parameters(config={}), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test(self.net, self.testloader)\n",
        "        return float(loss), len(self.testloader), {\"accuracy\": float(accuracy), \"loss\": float(loss)}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PTdzUBpkG3jE"
      },
      "source": [
        "The `get_parameters` function lets the server get the client's parameters. Inversely, the `set_parameters` function allows the server to send its parameters to the client. Finally, the `fit` function trains the model locally for the client, and the `evaluate` function tests the model locally and returns the relevant metrics."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kZDZ3KUaGapq"
      },
      "source": [
        "### Generating the clients\n",
        "\n",
        "In order to simulate the federated setting we need to provide a way to instantiate clients for our simulation. Here, it is very simple as every client will hold the same piece of data (this is not realistic, it is just used here for simplicity sakes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "y9A11kmafSwX"
      },
      "outputs": [],
      "source": [
        "trainloader, testloader = load_data(num_clients=2,num_samples_per_client=20)\n",
        "def client_fn(cid):\n",
        "    cid = int(cid)\n",
        "    net = AutoModelForSequenceClassification.from_pretrained(CHECKPOINT, num_labels=2).to(DEVICE)\n",
        "    return IMDBClient(net, trainloader[cid], testloader[cid])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7dcCPKDjaFt"
      },
      "source": [
        "## Starting the simulation\n",
        "\n",
        "We now have all the elements to start our simulation. The `weighted_average` function is there to provide a way to aggregate the metrics distributed amongst the clients (basically to display a nice average accuracy at the end of the training). We then define our strategy (here `FedAvg`, which will aggregate the clients weights by doing an average).\n",
        "\n",
        "Note that this is a very basic example, and a lot can be added or modified, it was just to showcase how simply we could federate a Hugging Face workflow using Flower. The number of clients and the data samples are intentionally very small in order to quickly run inside Colab, but keep in mind that everything can be tweaked and extended.\n",
        "\n",
        "Finally, `start_simulation` is used to start the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s6Jsw70Qe_yA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=3, no round_timeout\n",
            "2025-07-04 18:25:51,643\tINFO worker.py:1917 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 1.0, 'node:__internal_head__': 1.0, 'node:127.0.0.1': 1.0, 'memory': 22232645632.0, 'object_store_memory': 2147483648.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 133.90s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.0374693974852562\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.03673959374427795\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.03886908143758774\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(1, 0.45), (2, 0.525), (3, 0.475)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'loss': [(1, 0.0374693974852562),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (2, 0.03673959374427795),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (3, 0.03886908143758774)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.0374693974852562\n",
              "\tround 2: 0.03673959374427795\n",
              "\tround 3: 0.03886908143758774\n",
              "History (metrics, distributed, evaluate):\n",
              "{'accuracy': [(1, 0.45), (2, 0.525), (3, 0.475)],\n",
              " 'loss': [(1, 0.0374693974852562),\n",
              "          (2, 0.03673959374427795),\n",
              "          (3, 0.03886908143758774)]}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def weighted_average(metrics):\n",
        "  accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "  losses = [num_examples * m[\"loss\"] for num_examples, m in metrics]\n",
        "  examples = [num_examples for num_examples, _ in metrics]\n",
        "  return {\"accuracy\": sum(accuracies) / sum(examples), \"loss\": sum(losses) / sum(examples)}\n",
        "\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=1.0,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,\n",
        ")\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n",
        "    strategy=strategy,\n",
        "    client_resources={\"num_cpus\": 1, \"num_gpus\": 0},\n",
        "    ray_init_args={\"log_to_driver\": False, \"num_cpus\": 1, \"num_gpus\": 0}\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing pre-trained models: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForMaskedLM: ['albert.pooler.bias', 'albert.pooler.weight']\n",
            "- This IS expected if you are initializing AlbertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use mps:0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'score': 0.05570036172866821,\n",
              "  'token': 7178,\n",
              "  'token_str': 'excited',\n",
              "  'sequence': 'why people are getting so excited later in life.'},\n",
              " {'score': 0.034907858818769455,\n",
              "  'token': 4266,\n",
              "  'token_str': 'lucky',\n",
              "  'sequence': 'why people are getting so lucky later in life.'},\n",
              " {'score': 0.03208455443382263,\n",
              "  'token': 5056,\n",
              "  'token_str': 'scared',\n",
              "  'sequence': 'why people are getting so scared later in life.'},\n",
              " {'score': 0.02416936121881008,\n",
              "  'token': 4117,\n",
              "  'token_str': 'tired',\n",
              "  'sequence': 'why people are getting so tired later in life.'},\n",
              " {'score': 0.023810677230358124,\n",
              "  'token': 1700,\n",
              "  'token_str': 'happy',\n",
              "  'sequence': 'why people are getting so happy later in life.'}]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "unmasker = pipeline('fill-mask', model='albert-base-v2')\n",
        "unmasker(\"Why people are getting so [MASK] later in life.\")\n",
        "# unmasker(\"The woman worked as a [MASK].\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
