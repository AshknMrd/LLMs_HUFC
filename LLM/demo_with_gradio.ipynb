{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name\n",
    "\n",
    "\n",
    "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name\n",
    "\n",
    "\n",
    "# We instantiate the Textbox class\n",
    "textbox = gr.Textbox(label=\"Type your name here:\", placeholder=\"John Doe\", lines=2)\n",
    "\n",
    "gr.Interface(fn=greet, inputs=textbox, outputs=\"text\").launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat GPT like Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model = pipeline(\"text-generation\")\n",
    "\n",
    "\n",
    "def predict(prompt):\n",
    "    completion = model(prompt)[0][\"generated_text\"]\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"My favorite programming language is Python. You could even say that Python is the most popular programming language, and it was created to be used as a programming language.\\n\\nBut what if you used Python as your programming language? What if you used Java, Python, or some other programming language with a different syntax and semantics?\\n\\nIt's like if you used Java on a computer, you could write a Python program as if it were Java.\\n\\nI started learning the Java language using the Java Tutorial and saw a lot more programming in this language.\\n\\nI knew that programming in Java was very easy.\\n\\nHow did you get started programming in Python?\\n\\nMy first job was teaching a course on programming in Java.\\n\\nI read a lot of Python books. I've got a computer. I started to understand Java.\\n\\nHow did you get involved in Java?\\n\\nI got interested in programming through a lot of books. I've read a lot of books on Java.\\n\\nI learned a lot of Python.\\n\\nHow did you get into Python?\\n\\nI got into programming by following the Python Tutorial.\\n\\nI got into programming because I was fascinated by the concept of data structures. I learned that there's a kind of hierarchy of\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "predict(\"My favorite programming language is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(fn=predict, inputs=\"text\", outputs=\"text\").launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the Interface class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reversing audio example\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def reverse_audio(audio):\n",
    "    sr, data = audio\n",
    "    reversed_audio = (sr, np.flipud(data))\n",
    "    return reversed_audio\n",
    "\n",
    "\n",
    "mic = gr.Audio(sources=\"microphone\", type=\"numpy\", label=\"Speak here...\")\n",
    "gr.Interface(reverse_audio, mic, \"audio\").launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "notes = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "\n",
    "\n",
    "def generate_tone(note, octave, duration):\n",
    "    sr = 48000\n",
    "    a4_freq, tones_from_a4 = 440, 12 * (octave - 4) + (note - 9)\n",
    "    frequency = a4_freq * 2 ** (tones_from_a4 / 12)\n",
    "    duration = int(duration)\n",
    "    audio = np.linspace(0, duration, duration * sr)\n",
    "    audio = (20000 * np.sin(audio * (2 * np.pi * frequency))).astype(np.int16)\n",
    "    return (sr, audio)\n",
    "\n",
    "\n",
    "gr.Interface(\n",
    "    generate_tone,\n",
    "    [\n",
    "        gr.Dropdown(notes, type=\"index\"),\n",
    "        gr.Slider(minimum=4, maximum=6, step=1),\n",
    "        gr.Number(value=1, label=\"Duration in seconds\"),\n",
    "    ],\n",
    "    \"audio\",\n",
    ").launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, weâ€™ll load our speech recognition model using the pipeline() function from ðŸ¤— Transformers. If you need a quick refresher, you can go back to that section in Chapter 1. Next, weâ€™ll implement a transcribe_audio() function that processes the audio and returns the transcription. Finally, weâ€™ll wrap this function in an Interface with the Audio components for the inputs and just text for the output. Altogether, the code for this application is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 22aad52 (https://huggingface.co/facebook/wav2vec2-base-960h).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012d844c9869493eb3dd15074008ad03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e843dea9fe4d3688fdecf05707a6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8e6e3f02b64c08a2ca31acd3d61a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b869f4cbdd4b4813b1d39deff5e8e2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a3bbeed52a4c8a8ca85816d9508ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919a748a243746b283fc346cf6df76c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "\n",
    "model = pipeline(\"automatic-speech-recognition\")\n",
    "\n",
    "\n",
    "def transcribe_audio(audio):\n",
    "    transcription = model(audio)[\"text\"]\n",
    "    return transcription\n",
    "\n",
    "\n",
    "gr.Interface(\n",
    "    fn=transcribe_audio,\n",
    "    inputs=gr.Audio(type=\"filepath\"),\n",
    "    outputs=\"text\",\n",
    ").launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharing demos with others\n",
    "\n",
    "Now that youâ€™ve built a demo, youâ€™ll probably want to share it with others. Gradio demos can be shared in two ways: using a temporary share link or permanent hosting on Spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "title = \"Ask Rick a Question\"\n",
    "description = \"\"\"\n",
    "The bot was trained to answer questions based on Rick and Morty dialogues. Ask Rick anything!\n",
    "<img src=\"https://huggingface.co/spaces/course-demos/Rick_and_Morty_QA/resolve/main/rick.png\" width=200px>\n",
    "\"\"\"\n",
    "\n",
    "article = \"Check out [the original Rick and Morty Bot](https://huggingface.co/spaces/kingabzpro/Rick_and_Morty_Bot) that this demo is based off of.\"\n",
    "\n",
    "gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=\"textbox\",\n",
    "    outputs=\"text\",\n",
    "    title=title,\n",
    "    description=description,\n",
    "    article=article,\n",
    "    examples=[[\"What are you doing?\"], [\"Where should we time travel to?\"]],\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not create share link. Missing file: /Users/ashkanm/.cache/huggingface/gradio/frpc/frpc_darwin_arm64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_darwin_arm64\n",
      "2. Rename the downloaded file to: frpc_darwin_arm64_v0.3\n",
      "3. Move the file to this location: /Users/ashkanm/.cache/huggingface/gradio/frpc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gr.Interface(classify_image, \"image\", \"label\").launch(share=True)\n",
    "# For sharing a public link: \n",
    "\n",
    "gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=\"textbox\",\n",
    "    outputs=\"text\",\n",
    "    title=title,\n",
    "    description=description,\n",
    "    article=article,\n",
    "    examples=[[\"What are you doing?\"], [\"Where should we time travel to?\"]],\n",
    ").launch(share=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hosting your demo on Hugging Face Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'demo_test'...\n",
      "remote: Enumerating objects: 4, done.\u001b[K\n",
      "remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
      "Unpacking objects: 100% (4/4), 1.29 KiB | 329.00 KiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "# Made a new gradio space on huggingface and \n",
    "!git clone https://huggingface.co/spaces/AshknMrd/demo_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add app.y # and all the other file \n",
    "!git commit -m \"Add application file\"    \n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import gradio as gr\n",
    "from torch import nn\n",
    "\n",
    "LABELS = Path(\"Sketch_Recognition_demo/class_names.txt\").read_text().splitlines()\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 3, padding=\"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32, 64, 3, padding=\"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(64, 128, 3, padding=\"same\"),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(1152, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, len(LABELS)),\n",
    ")\n",
    "state_dict = torch.load(\"Sketch_Recognition_demo/pytorch_model.bin\", map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def predict(im):\n",
    "    x = torch.tensor(im, dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.0\n",
    "    with torch.no_grad():\n",
    "        out = model(x)\n",
    "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
    "    values, indices = torch.topk(probabilities, 5)\n",
    "    return {LABELS[i]: v.item() for i, v in zip(indices, values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = gr.Interface(\n",
    "    predict,\n",
    "    inputs=\"sketchpad\",\n",
    "    outputs=\"label\",\n",
    "    theme=\"huggingface\",\n",
    "    title=\"Sketch Recognition\",\n",
    "    description=\"Who wants to play Pictionary? Draw a common object like a shovel or a laptop, and the algorithm will guess in real time!\",\n",
    "    article=\"<p style='text-align: center'>Sketch Recognition | Demo Model</p>\",\n",
    "    live=True,\n",
    ")\n",
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
